{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import os\n",
    "#import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms,datasets\n",
    "from model import Net\n",
    "\n",
    "DATA_DIR= \"../../../datashare/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self,img_names ,img_dir, transform= transforms.ToTensor(), target_transform=None):\n",
    "        self.img_labels =img_names\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels[idx])\n",
    "        image=Image.open(img_path)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image\n",
    "\n",
    "\n",
    "class VideoFrameDataset(Dataset):\n",
    "    def __init__(self,fold_num,f,top=True) -> None:\n",
    "        super().__init__()\n",
    "        self.fold_num=fold_num\n",
    "        self.file_name=f\n",
    "        self.gesture_mapping= {\"G0\":0,\"G1\":1,\"G2\":2,\"G3\":3,\"G4\":4,\"G5\":5}\n",
    "        self.topOrSide=\"_\"+(\"top\" if top else \"side\")\n",
    "        self.shape=[1280, 36,6]\n",
    "\n",
    "        if f not in ['P032_tissue2.npy','P025_balloon2.npy']:\n",
    "            data = np.load(DATA_DIR+\"APAS/features/fold\"+self.fold_num+\"/\"+f)\n",
    "            data = np.transpose(data)\n",
    "            \n",
    "            n_f=data.shape[0]\n",
    "            \n",
    "            data_k = np.load(DATA_DIR+\"APAS/kinematics_npy/\"+f)\n",
    "            data_k = np.transpose(data_k)\n",
    "            k_f=data_k.shape[0]\n",
    "            missing_frames_number = n_f-k_f\n",
    "            if missing_frames_number > 0:\n",
    "                missing_frames=np.random.choice(range(k_f),missing_frames_number)\n",
    "                data_k=np.insert(data_k,missing_frames,[data_k[i,:] for i in missing_frames],axis=0) \n",
    "            elif missing_frames_number < 0:\n",
    "                missing_frames=np.random.choice(range(n_f),-missing_frames_number)\n",
    "                data=np.insert(data,missing_frames,[data[i,:] for i in missing_frames],axis=0)\n",
    "             #frames_vec=torch.cat((torch.from_numpy(data),torch.from_numpy(data_k)),axis=0)\n",
    "            data=torch.from_numpy(data)\n",
    "            data_k=torch.from_numpy(data_k)\n",
    "            labels=[]\n",
    "            frames_path=DATA_DIR+\"APAS/frames/\"+f.split('.')[0]+f\"{self.topOrSide}/\"                  \n",
    "            frames= sorted(os.listdir(frames_path))\n",
    "            \n",
    "            \n",
    "            \n",
    "            #normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "            #                         std=[0.229, 0.224, 0.225])\n",
    "\n",
    "            framesdataset=CustomImageDataset(img_names=frames,img_dir=frames_path,\n",
    "                                             transform=transforms.Compose([\n",
    "            #        transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "            #        normalize,\n",
    "                ]))\n",
    "           \n",
    "            \n",
    "            with open(DATA_DIR+\"APAS/transcriptions_gestures/\"+f.split('.')[0]+\".txt\", \"r\") as file:\n",
    "                labels_data = file.readlines()\n",
    "            for line in labels_data:\n",
    "                values = line[:-1].split()\n",
    "                if int(values[1]) > len(data):\n",
    "                    ul = len(data)\n",
    "                else:\n",
    "                    ul = values[1]\n",
    "                if int(values[0]) == 0:\n",
    "                    start = 1\n",
    "                else:\n",
    "                    start = int(values[0])\n",
    "                \n",
    "                for i in range(start,int(ul)+1):\n",
    "                    labels.append(self.gesture_mapping[values[2]])    \n",
    "           \n",
    "            missing_frames_number = len(labels)-len(framesdataset)\n",
    "            if  missing_frames_number > 0:\n",
    "                    missing_frames=np.random.choice(len(framesdataset),missing_frames_number)\n",
    "                    for index in missing_frames:\n",
    "                        framesdataset.img_labels.insert(index,framesdataset.img_labels[index])  \n",
    "            self.vid=framesdataset\n",
    "            self.f_e=data\n",
    "            self.f_k=data_k \n",
    "            self.labels=labels\n",
    "        print(f,len(framesdataset),len(labels))\n",
    "        assert len(framesdataset) ==len(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "       \n",
    "        #return self.f_k[idx,:],self.f_e[idx,:],self.labels[idx]\n",
    "\n",
    "        return self.vid[idx],self.f_k[idx,:],self.f_e[idx,:],self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model,path,args):\n",
    "    model = model(*args)\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldNum=\"0\"\n",
    "top=True\n",
    "videoname=\"P016_tissue1.npy\"\n",
    "weight_value=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P016_tissue1.npy 6751 6751\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vid=VideoFrameDataset(f=videoname,fold_num=foldNum,top=top)\n",
    "num_of_features_e,num_of_features_k,num_of_classes=vid.shape\n",
    "\n",
    "net = Net(num_of_classes=num_of_classes,num_of_features_e=num_of_features_e,num_of_features_k=num_of_features_k,weight1=weight_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_video(model,dataset,fps=30):\n",
    "    labels_dict=vid.gesture_mapping\n",
    "    x,y,w,h = 0,0,400,25\n",
    "    img_array=[]\n",
    "    for data in dataset:\n",
    "        frame,input_e,input_v,label=data\n",
    "        height, width, layers = frame.shape\n",
    "        size = (width, height)\n",
    "        pred=model(input_e,input_v)\n",
    "        labels_dict[pred]\n",
    "        cv2.putText(img=frame, text=\"Pred:\" +labels_dict[pred]+ \"Label:\" +labels_dict[label], org=(x + int(w / 15), y + int(h / 3)),\n",
    "                fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                fontScale=0.5, color=(0, 0, 255), thickness=1)\n",
    "        img_array.append(frame)\n",
    "    out = cv2.VideoWriter(f'{videoname}.mp4', cv2.VideoWriter_fourcc(*'DIVX'), fps, size)\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.load(DATA_DIR+\"APAS\"+\"/kinematics_npy\"+\"/P018_balloon1.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(model,data_loader,frames_loader,labels_dict):\n",
    "    x,y,w,h = 0,0,400,25\n",
    "    img_array=[]\n",
    "    for data,frame in zip(data_loader,frames_loader):\n",
    "        input_e,input_v,label=data\n",
    "        height, width, layers = frame.shape\n",
    "        size = (width, height)\n",
    "        pred=model(input_e,input_v)\n",
    "        labels_dict[pred]\n",
    "        cv2.putText(img=frame, text=\"Pred:\" +labels_dict[pred]+ \"Label:\" +labels_dict[label], org=(x + int(w / 15), y + int(h / 3)),\n",
    "                fontFace=cv2.FONT_HERSHEY_DUPLEX,\n",
    "                fontScale=0.5, color=(0, 0, 255), thickness=1)\n",
    "        img_array.append(frame)\n",
    "    out = cv2.VideoWriter('P026_tissue1_new.mp4', cv2.VideoWriter_fourcc(*'DIVX'), 15, size)\n",
    "\n",
    "    for i in range(len(img_array)):\n",
    "        out.write(img_array[i])\n",
    "    out.release()\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3476188823.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    def pred(model,filename):\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def pred(model,filename):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 3934)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=np.load(DATA_DIR+\"APAS\"+\"/features\"+\"/fold0\"+\"/P032_tissue2.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1280, 6911)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bad pipe message: %s [b't(\\xb3\\x11`\\x9d\\xea\"\\x12l\\x90\\xbe\\xbag\\x1f\\xb8\\xc4\\x89 ~edt`\\'\\x0c\\xa3\\x18QO\\xcb.\\x9e\\xd9\\xcdlX\\x88\\xe3\\x18\\xca\\xc5\\xc8\\xe8\\x94\\xc8\"T\\x04\\xec\\xdc\\x00\\x08\\x13\\x02\\x13\\x03\\x13\\x01\\x00\\xff\\x01\\x00\\x00\\x8f\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00']\n",
      "Bad pipe message: %s [b\"\\xa0^\\xdb\\xb64vDE\\xf6\\xe8\\xdb\\xce\\xf6\\xf6\\xc2\\x1a{\\xea\\x00\\x00|\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0#\\xc0'\\x00g\\x00@\\xc0\\n\\xc0\\x14\\x009\\x008\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00<\\x005\\x00/\\x00\\x9a\\x00\\x99\\xc0\\x07\\xc0\\x11\\x00\\x96\\x00\\x05\\x00\\xff\\x01\\x00\\x00j\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.1\\x00\\x0b\"]\n",
      "Bad pipe message: %s [b\"\\x7f\\xca\\xd9\\xb4\\x00\\xc03\\x96\\rh\\xf8\\x07xK\\xc5f\\x16\\xe2\\x00\\x00\\xa6\\xc0,\\xc00\\x00\\xa3\\x00\\x9f\\xcc\\xa9\\xcc\\xa8\\xcc\\xaa\\xc0\\xaf\\xc0\\xad\\xc0\\xa3\\xc0\\x9f\\xc0]\\xc0a\\xc0W\\xc0S\\xc0+\\xc0/\\x00\\xa2\\x00\\x9e\\xc0\\xae\\xc0\\xac\\xc0\\xa2\\xc0\\x9e\\xc0\\\\\\xc0`\\xc0V\\xc0R\\xc0$\\xc0(\\x00k\\x00j\\xc0s\\xc0w\\x00\\xc4\\x00\\xc3\\xc0#\\xc0'\\x00g\\x00@\\xc0r\\xc0v\\x00\\xbe\\x00\\xbd\\xc0\\n\\xc0\\x14\\x009\\x008\\x00\\x88\\x00\\x87\\xc0\\t\\xc0\\x13\\x003\\x002\\x00\\x9a\\x00\\x99\\x00E\\x00D\\xc0\\x07\\xc0\\x11\\xc0\\x08\\xc0\\x12\\x00\\x16\\x00\\x13\\x00\\x9d\\xc0\\xa1\\xc0\\x9d\\xc0Q\\x00\\x9c\\xc0\\xa0\\xc0\\x9c\\xc0P\\x00=\\x00\\xc0\"]\n",
      "Bad pipe message: %s [b'R\\x1f\\x94\\x86\\xbd\\x1amw1lN\\x19FxZ\\x8b\\x0c\\xc3\\x00\\x00>\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\xc0\\x0f\\xc0\\x05\\x005\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00\\x96\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\x00\\xff\\x02\\x01\\x00\\x00C\\x00\\x00\\x00\\x0e\\x00\\x0c\\x00\\x00\\t127.0.0.', b'\\x0b\\x00\\x04\\x03\\x00\\x01\\x02\\x00\\n\\x00\\x1c\\x00\\x1a\\x00\\x17\\x00\\x19\\x00\\x1c\\x00\\x1b\\x00\\x18\\x00\\x1a\\x00\\x16\\x00\\x0e\\x00\\r\\x00\\x0b\\x00\\x0c\\x00\\t\\x00\\n\\x00#\\x00\\x00\\x00\\x0f\\x00\\x01\\x01']\n",
      "Bad pipe message: %s [b'8\\xa5\\xe7\\x05\\x98:\\xaf\\xb2\\x0e\\xeav\\x84q\\x08\\x1f\\x97\\xabW\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\\x12\\xc0\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03\\x00\\n\\x00\\x15\\x00\\x12\\x00\\x0f\\x00\\x0c\\x00', b'\\t\\x00\\x14\\x00\\x11\\x00\\x19\\x00\\x08\\x00\\x06\\x00\\x17\\x00\\x03\\xc0\\x10\\xc0\\x06\\xc0\\x15\\xc0\\x0b\\xc0\\x01']\n",
      "Bad pipe message: %s [b'\\xa6\\x0eU\\x1f\\xe8a\\xb0\\xb8i\\xf2\\x08\\xda\"\\xdc~\\xb6\\x01\\x8f\\x00\\x00\\xa2\\xc0\\x14\\xc0\\n\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00:\\x00\\x89\\xc0\\x0f\\xc0\\x05\\x005\\x00\\x84\\xc0\\x13\\xc0\\t\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x004\\x00\\x9b\\x00F\\xc0\\x0e\\xc0\\x04\\x00/\\x00\\x96\\x00A']\n",
      "Bad pipe message: %s [b'\\xa0\\xbdi&\\xa1\\xc4\\x86\\xf90\\xbd\\x9bUO,\\x997\\xe7\\x9f\\x00\\x00\\xf4\\xc00\\xc0,\\xc0(\\xc0$\\xc0\\x14\\xc0\\n\\x00']\n",
      "Bad pipe message: %s [b\"\\xa3\\x00\\xa1\\x00\\x9f\\x00k\\x00j\\x00i\\x00h\\x009\\x008\\x007\\x006\\x00\\x88\\x00\\x87\\x00\\x86\\x00\\x85\\xc0\\x19\\x00\\xa7\\x00m\\x00:\\x00\\x89\\xc02\\xc0.\\xc0*\\xc0&\\xc0\\x0f\\xc0\\x05\\x00\\x9d\\x00=\\x005\\x00\\x84\\xc0/\\xc0+\\xc0'\\xc0#\\xc0\\x13\\xc0\\t\\x00\\xa4\\x00\\xa2\\x00\\xa0\\x00\\x9e\\x00g\\x00@\\x00?\\x00>\\x003\\x002\\x001\\x000\\x00\\x9a\\x00\\x99\\x00\\x98\\x00\\x97\\x00E\\x00D\\x00C\\x00B\\xc0\\x18\\x00\\xa6\\x00l\\x004\\x00\\x9b\\x00F\\xc01\\xc0-\\xc0)\\xc0%\\xc0\\x0e\\xc0\\x04\\x00\\x9c\\x00<\\x00/\\x00\\x96\\x00A\\x00\\x07\\xc0\\x11\\xc0\\x07\\xc0\\x16\\x00\\x18\\xc0\\x0c\\xc0\\x02\\x00\\x05\\x00\\x04\\xc0\"]\n",
      "Bad pipe message: %s [b'\\x08\\x00\\x16\\x00\\x13\\x00\\x10\\x00\\r\\xc0\\x17\\x00\\x1b\\xc0\\r\\xc0\\x03']\n"
     ]
    }
   ],
   "source": [
    "b.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azureml_py38_PT_and_TF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a7c85737b377fc99f560e467a2834a263f428933c7e0528ef7ecc6f93a38afad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
